{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "837fa786",
   "metadata": {},
   "source": [
    "# Машинное обучение для текстов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3b6346",
   "metadata": {},
   "source": [
    "# Задача"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cd3439",
   "metadata": {},
   "source": [
    "Интернет-магазин добавил возможность комментирования и дополнения описания своих товаров для пользователей. Необходимо создать инструмент для поиска токсичных комментариев и отправки их на модерацию, то есть обучить модель на классификацию комментариев на позитивные и негативные."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c98461",
   "metadata": {},
   "source": [
    "# Требования"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc391df4",
   "metadata": {},
   "source": [
    "- метрика f1 должна быть не меньше 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c24ad1e",
   "metadata": {},
   "source": [
    "# Шаг 1. Загрузка, анализ и подготовка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae8221cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\micha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\micha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\micha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\omw-1.4.zip.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "# import numpy as np\n",
    "import time\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6442985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic\n",
       "0       Explanation\\nWhy the edits made under my usern...      0\n",
       "1       D'aww! He matches this background colour I'm s...      0\n",
       "2       Hey man, I'm really not trying to edit war. It...      0\n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4       You, sir, are my hero. Any chance you remember...      0\n",
       "...                                                   ...    ...\n",
       "159566  \":::::And for the second time of asking, when ...      0\n",
       "159567  You should be ashamed of yourself \\n\\nThat is ...      0\n",
       "159568  Spitzer \\n\\nUmm, theres no actual article for ...      0\n",
       "159569  And it looks like it was actually you who put ...      0\n",
       "159570  \"\\nAnd ... I really don't think you understand...      0\n",
       "\n",
       "[159571 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    data = pd.read_csv('/datasets/toxic_comments.csv')\n",
    "except FileNotFoundError:\n",
    "    data = pd.read_csv('toxic_comments.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d53c4a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1904d3f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143346\n",
       "1     16225\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f3ba91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['toxic'] = pd.to_numeric(data['toxic'], downcast='integer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9603894",
   "metadata": {},
   "source": [
    "Как видно из общего анализа данных, негативных комментариев всего лишь 10% от общего числа записей. Это необходимо будет учитывать. Также изменим тип `toxic` для уменьшения занимаемой памяти"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "570d3b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.tokenize.wordpunct_tokenize\n",
    "wnl = nltk.WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16292c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_prep_text(text):\n",
    "    text = re.sub(r\"[^a-zA-Z ]\", \" \", text).strip().lower()\n",
    "    tokens = [wnl.lemmatize(token) for token in tokenizer(text)]\n",
    "    lemmas = ' '.join(tokens)\n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5932db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>clear_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>d aww he match this background colour i m seem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>hey man i m really not trying to edit war it s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>more i can t make any real suggestion on impro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>0</td>\n",
       "      <td>and for the second time of asking when your vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>0</td>\n",
       "      <td>you should be ashamed of yourself that is a ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>0</td>\n",
       "      <td>spitzer umm there no actual article for prosti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>0</td>\n",
       "      <td>and it look like it wa actually you who put on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>0</td>\n",
       "      <td>and i really don t think you understand i came...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        toxic                                         clear_text\n",
       "0           0  explanation why the edits made under my userna...\n",
       "1           0  d aww he match this background colour i m seem...\n",
       "2           0  hey man i m really not trying to edit war it s...\n",
       "3           0  more i can t make any real suggestion on impro...\n",
       "4           0  you sir are my hero any chance you remember wh...\n",
       "...       ...                                                ...\n",
       "159566      0  and for the second time of asking when your vi...\n",
       "159567      0  you should be ashamed of yourself that is a ho...\n",
       "159568      0  spitzer umm there no actual article for prosti...\n",
       "159569      0  and it look like it wa actually you who put on...\n",
       "159570      0  and i really don t think you understand i came...\n",
       "\n",
       "[159571 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['clear_text'] = data['text'].apply(clear_prep_text)\n",
    "data.drop('text', axis=1, inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3dc60d",
   "metadata": {},
   "source": [
    "# Шаг 2. Обучение моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77a077e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=.2, random_state=12345, stratify=data['toxic'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b21a3a37",
   "metadata": {},
   "source": [
    "## SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c12e6023",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_sgd = Pipeline(\n",
    "    [\n",
    "        (\"vect\", CountVectorizer()),\n",
    "        (\"tfidf\", TfidfTransformer()),\n",
    "        (\"SGD\", SGDClassifier())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b64502c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_sgd = {\n",
    "    \"vect__max_df\": (0.75,),\n",
    "    # 'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    \"vect__ngram_range\": ((1, 2),),  # unigrams or bigrams\n",
    "    # 'tfidf__use_idf': (True, False),\n",
    "    'tfidf__norm': ('l2',),\n",
    "    \"SGD__max_iter\": (20,),\n",
    "    \"SGD__alpha\": (0.000001,),\n",
    "    \"SGD__penalty\": ('elasticnet',),\n",
    "    # 'SGD__max_iter': (10, 50, 80),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f935c3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_sgd = GridSearchCV(pipeline_sgd, parameters_sgd, n_jobs=-1, verbose=1, scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f94922d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Work time: 44.06\n",
      "Best F1 score of SGDClassifier on train: 0.7929049905631452\n",
      "{'SGD__alpha': 1e-06, 'SGD__max_iter': 20, 'SGD__penalty': 'elasticnet', 'tfidf__norm': 'l2', 'vect__max_df': 0.75, 'vect__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "gs_sgd.fit(train['clear_text'], train['toxic'])\n",
    "print(f'Work time: {round(time.time() - start, 2)}')\n",
    "print(f'Best F1 score of SGDClassifier on train: {gs_sgd.best_score_}')\n",
    "print(gs_sgd.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a02d786",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1 score of SGDClassifier on test: 0.7988602078444519\n"
     ]
    }
   ],
   "source": [
    "predict = gs_sgd.predict(test['clear_text'])\n",
    "print(f'Best F1 score of SGDClassifier on test: {f1_score(test.toxic, predict)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059b82e9",
   "metadata": {},
   "source": [
    "## LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64889766",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_lr = Pipeline(\n",
    "    [\n",
    "        (\"vect\", CountVectorizer()),\n",
    "        (\"tfidf\", TfidfTransformer()),\n",
    "        (\"lr\", LogisticRegression())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a39e4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_lr = {\n",
    "    \"vect__max_df\": (0.75,),\n",
    "    # 'vect__max_features': (None, 5000, 10000, 50000),\n",
    "    \"vect__ngram_range\": ((1, 2),), \n",
    "    # 'tfidf__use_idf': (True, False),\n",
    "    'tfidf__norm': ('l2',),\n",
    "    \"lr__C\": (100,)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "456595ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_lr = GridSearchCV(pipeline_lr, parameters_lr, n_jobs=-1, verbose=1, scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e70aa69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Work time: 143.49\n",
      "Best F1 score of LogisticRegression on train: 0.7899803589204651\n",
      "{'lr__C': 100, 'tfidf__norm': 'l2', 'vect__max_df': 0.75, 'vect__ngram_range': (1, 2)}\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "gs_lr.fit(train['clear_text'], train['toxic'])\n",
    "print(f'Work time: {round(time.time() - start, 2)}')\n",
    "print(f'Best F1 score of LogisticRegression on train: {gs_lr.best_score_}')\n",
    "print(gs_lr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5e0a4ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1 score of LogisticRegression on test: 0.8028805895159941\n"
     ]
    }
   ],
   "source": [
    "predict = gs_lr.predict(test['clear_text'])\n",
    "print(f'Best F1 score of LogisticRegression on test: {f1_score(test.toxic, predict)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5dea85",
   "metadata": {},
   "source": [
    "<b>Вывод</b>\n",
    "- данные загружены\n",
    "- текстовые данные лемантизированы\n",
    "- подобраны параметры к векторизации и моделям SGDClassifier и LogisticRegression. f1 в обоих случаях составила 0.8 (оставлены только лучшие параметры для уменьшения времени расчетов)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
